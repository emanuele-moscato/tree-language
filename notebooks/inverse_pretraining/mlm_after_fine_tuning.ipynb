{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19124bc-a56a-4440-8b81-aa0738eb3d94",
   "metadata": {},
   "source": [
    "# MLM training starting from a trained classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d32f5-760d-4e10-a521-6fd4f9cac0eb",
   "metadata": {},
   "source": [
    "__Objective:__ start from a model for classification (root inference) and swap its head to get a model able to perform MLM for further MLM training (essentially it's the reverse operation w.r.t. pre-training + fine-tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab3c0c-857f-434a-8074-ca723b03c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append('../../modules/')\n",
    "\n",
    "from utilities import read_data\n",
    "from pytorch_utilities import load_checkpoint\n",
    "from models import TransformerClassifier, replace_classification_head_with_decoder\n",
    "from model_evaluation_tree_language import compute_accuracy\n",
    "from masked_language_modeling import mask_sequences, compute_masked_accuracy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19134a40-66ac-4edb-8633-7d727878314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/mlm_data/slrm_data/labeled_data_fixed_4_8_1.0_0.00000.npy'\n",
    "VALIDATION_DATA_PATH = '../../data/mlm_data/slrm_data/labeled_data_fixed_validation_4_8_1.0_0.00000.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf930275-aee7-46f5-97da-bf4fcc834c97",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea295b9f-5449-45be-9adf-9fa66084782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, sigma, epsilon, roots_train, leaves_train, rho = read_data(DATA_PATH, seed=0)\n",
    "_, _, _, _, roots_test, leaves_test, rho_validation = read_data(VALIDATION_DATA_PATH, seed=0)\n",
    "\n",
    "leaves_test = leaves_test[:5000, :]\n",
    "\n",
    "# Data preprocessing.\n",
    "leaves_train = torch.from_numpy(leaves_train).to(device=device).to(dtype=torch.int64)\n",
    "leaves_test = torch.from_numpy(leaves_test).to(device=device).to(dtype=torch.int64)\n",
    "\n",
    "roots_train = torch.nn.functional.one_hot(\n",
    "    torch.from_numpy(roots_train).to(dtype=torch.int64), num_classes=q\n",
    ").to(dtype=torch.float32).to(device=device)\n",
    "roots_test = torch.nn.functional.one_hot(\n",
    "    torch.from_numpy(roots_test).to(dtype=torch.int64), num_classes=q\n",
    ").to(dtype=torch.float32).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55202e4-7d0b-455d-b73f-b45d882cf72f",
   "metadata": {},
   "source": [
    "Generate a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d54c6-b5eb-483c-bdb8-5ceca66ebcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.arange(q).to(dtype=torch.int64)\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e4ee6-1ad9-4a5e-a4b4-c9586162de8a",
   "metadata": {},
   "source": [
    "Instantiate a classification model (not trained, for simplicity) - in the actual case this will be loaded with `load_checkpoint`.\n",
    "\n",
    "**Note:** the classification model doesn't know anything about the `<mask>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844ab66-d254-417d-bee6-08b1e1e175e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = int(2 ** k)\n",
    "embedding_size = 128\n",
    "vocab_size = vocab.shape[0]\n",
    "\n",
    "classification_model = TransformerClassifier(\n",
    "    seq_len=seq_len,\n",
    "    embedding_size=embedding_size,\n",
    "    n_tranformer_layers=2,  # Good: 4\n",
    "    n_heads=1,\n",
    "    vocab_size=vocab_size,\n",
    "    encoder_dim_feedforward=2 * embedding_size,\n",
    "    positional_encoding=True,\n",
    "    n_special_tokens=0,  # We assume the special tokens correspond to the last `n_special_tokens` indices.\n",
    "    embedding_agg='mean',\n",
    "    decoder_hidden_sizes=[64],  # Good: [64]\n",
    "    decoder_activation='relu',  # Good: 'relu'\n",
    "    decoder_output_activation='identity'\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff5e50a-3f9d-4e95-824f-92b9385208b3",
   "metadata": {},
   "source": [
    "Test the untrained classification model on the validation data (accuracy should be $\\sim 1/q$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0c15c-e458-40a8-aab7-9d38c36d7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output shape: (batch_shape, q) (q logits for each sample in the batch).\n",
    "with torch.no_grad():\n",
    "    val_pred = classification_model(leaves_test)\n",
    "\n",
    "val_pred.shape, compute_accuracy(val_pred, leaves_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d95042-9530-43e2-a700-6c8863b97031",
   "metadata": {},
   "source": [
    "Replace the classification head with an MLM head.\n",
    "\n",
    "See: https://discuss.pytorch.org/t/expand-an-existing-embedding-and-linear-layer-nan-loss-value/55670/2\n",
    "\n",
    "Notes:\n",
    "- Assuming the vocabulary used for the classification model did not contain the `<mask>` token, when switching to an MLM model the input embedding layer is enlarged to take one more token (the mask) into account. The weights correponding to the other tokens (already seen) are copied from the original layer.\n",
    "- We assume the classification model has seen symbols `0, ..., q-1` and that the mask token corresponds to symbol `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527221ce-fad8-44a6-8cf0-7f57365fdba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_model = replace_classification_head_with_decoder(\n",
    "    original_model=classification_model,\n",
    "    n_classes=q,\n",
    "    device=device,\n",
    "    decoder_hidden_dim=[64]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0c6cd-f0bf-4367-a764-05c1e26d23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output shape: (batch_size, seq_len, embedding_size).\n",
    "with torch.no_grad():\n",
    "    mlm_pred = mlm_model(leaves_test)\n",
    "\n",
    "mlm_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ad9e5-7db8-41d7-8944-45f177bb3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function assumes that the mask token corresponds to value `q`.\n",
    "mask_idx = max(vocab) + 1\n",
    "\n",
    "leaves_test_masked, mask = mask_sequences(\n",
    "    sequences=leaves_test,\n",
    "    mask_rate=0.5,\n",
    "    reshaped_mask_idx=mask_idx * torch.ones_like(leaves_test),\n",
    "    device=device,\n",
    "    single_mask=False\n",
    ")\n",
    "\n",
    "# Output shape: (batch_size, seq_len, embedding_size).\n",
    "with torch.no_grad():\n",
    "    mlm_pred_masked = mlm_model(leaves_test_masked).detach()\n",
    "\n",
    "mlm_pred_masked.shape, compute_masked_accuracy(mlm_pred_masked, leaves_test, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
