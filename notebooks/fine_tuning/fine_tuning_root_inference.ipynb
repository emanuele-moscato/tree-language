{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "423912fd-7657-4519-a064-6fc77f59f5f6",
   "metadata": {},
   "source": [
    "# Fine-tuning for root inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c191253-a463-4119-b765-99bdd41142f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append('../../modules/')\n",
    "\n",
    "from logger_tree_language import get_logger\n",
    "from pytorch_utilities import load_checkpoint\n",
    "from models import replace_decoder_with_classification_head, freeze_encoder_weights\n",
    "from training import train_model\n",
    "from plotting import plot_training_history\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logger = get_logger('fine_tuning_root_inference')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9393310-ae36-458f-af40-e017d3018fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINING_DATA_PATH = '../../data/mlm_data/slrm_data/labeled_data_fixed_4_8_1.0_0.00000.npy'\n",
    "DATA_PATH = '../../data/mlm_data/slrm_data/labeled_data_fixed_validation_4_8_1.0_0.00000.npy'\n",
    "MODEL_DIR = '../../models/mlm_pretraining_1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e82cd3-7602-4a6c-a627-d2152be956d9",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1a5381-75ac-4aaa-a16f-273a5251500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 18:11:47,298 - fine_tuning_root_inference - INFO - N training samples: 48000 | N test samples: 2000\n"
     ]
    }
   ],
   "source": [
    "q, k, sigma, epsilon, roots_seeds, leaves_seeds, rho_seeds = np.load(DATA_PATH, allow_pickle=True)\n",
    "\n",
    "# The last index corresponds to the seed that generated the\n",
    "# data/transition tensors: select one.\n",
    "seed = 0\n",
    "\n",
    "shuffled_indices = np.random.choice(range(leaves_seeds.shape[1]), leaves_seeds.shape[1], replace=False)\n",
    "\n",
    "roots = roots_seeds[:, seed]\n",
    "roots = roots[shuffled_indices]\n",
    "\n",
    "leaves = leaves_seeds[..., seed].T\n",
    "leaves = leaves[shuffled_indices, :]\n",
    "rho = rho_seeds[..., seed]\n",
    "\n",
    "# Train-test split.\n",
    "n_samples_test = 2000\n",
    "\n",
    "leaves_train = leaves[:-n_samples_test, :]\n",
    "roots_train = roots[:-n_samples_test]\n",
    "\n",
    "leaves_test = leaves[-n_samples_test:, :]\n",
    "roots_test = roots[-n_samples_test:]\n",
    "\n",
    "logger.info(\n",
    "    f'N training samples: {leaves_train.shape[0]}'\n",
    "    f' | N test samples: {leaves_test.shape[0]}'\n",
    ")\n",
    "\n",
    "# Data preprocessing.\n",
    "leaves_train = torch.from_numpy(leaves_train).to(device=device).to(dtype=torch.int64)\n",
    "leaves_test = torch.from_numpy(leaves_test).to(device=device).to(dtype=torch.int64)\n",
    "\n",
    "roots_train = torch.from_numpy(roots_train).to(device=device).to(dtype=torch.int64)\n",
    "roots_test = torch.from_numpy(roots_test).to(device=device).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959a807-af71-4854-912a-01b3666cc9dc",
   "metadata": {},
   "source": [
    "Load pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70fe204e-0100-4df2-b310-de7a04fa0d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 18:11:47,538 - fine_tuning_root_inference - INFO - Selected checkpoint: mlm_pretraining_1_epoch_6000.pt\n",
      "/home/moscato/miniconda3/envs/tree-language/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "checkpoint_epochs = sorted([\n",
    "    int(f.split('_')[-1].split('.')[0])\n",
    "    for f in os.listdir(MODEL_DIR)\n",
    "    if '.pt' in f\n",
    "])\n",
    "\n",
    "selected_checkpoint_epoch = checkpoint_epochs[-1]\n",
    "\n",
    "checkpoint_id = [f for f in os.listdir(MODEL_DIR) if f'{selected_checkpoint_epoch}.pt' in f][0]\n",
    "\n",
    "logger.info(f'Selected checkpoint: {checkpoint_id}')\n",
    "\n",
    "pretrained_model, _, training_history = load_checkpoint(\n",
    "    MODEL_DIR,\n",
    "    checkpoint_id,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e55cc-2d06-438e-ba64-a9c1f35d8999",
   "metadata": {},
   "source": [
    "Replace the pretrained model's head with a new classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8385be1-f55e-41f7-a892-d5804092aac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_embedding | N parameters: 640 | Parameters trainable: False\n",
      "positional_embedding | N parameters: 0 | Parameters trainable: True\n",
      "encoder_layer | N parameters: 132480 | Parameters trainable: False\n",
      "transformer_encoder | N parameters: 264960 | Parameters trainable: False\n",
      "embedding_agg_layer | N parameters: 0 | Parameters trainable: True\n",
      "decoder | N parameters: 2099428 | Parameters trainable: True\n"
     ]
    }
   ],
   "source": [
    "classification_model = replace_decoder_with_classification_head(\n",
    "    pretrained_model,\n",
    "    n_classes=q,\n",
    "    device=device,\n",
    "    head_hidden_dim=[64, 32],\n",
    "    head_activation='relu'\n",
    ")\n",
    "\n",
    "freeze_encoder_weights(classification_model, trainable_modules=['decoder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21962a8-83ab-444e-9dae-c3adff3ebfc0",
   "metadata": {},
   "source": [
    "Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4560d2d0-ef07-41a3-9a0b-f955432475a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 18:11:49,389 - fine_tuning_root_inference - INFO - Initial accuracy: 0.2510000169277191\n",
      "2024-05-02 18:11:49,390 - fine_tuning_root_inference - INFO - Training model\n",
      "100%|███████████████████| 10/10 [00:59<00:00,  5.94s/it, training_accuracy=tensor(0.1697), training_loss=tensor(1.3362), val_accuracy=tensor(0.2870, device='cuda:0'), val_loss=tensor(1.3652, device='cuda:0')]\n",
      "2024-05-02 18:12:48,748 - fine_tuning_root_inference - INFO - Last epoch: 10\n"
     ]
    }
   ],
   "source": [
    "initial_accuracy = (\n",
    "    torch.argmax(classification_model(leaves_test), dim=-1).detach() == roots_test\n",
    ").to(dtype=torch.float32).mean().to(device='cpu')\n",
    "\n",
    "logger.info(f'Initial validation accuracy: {initial_accuracy}')\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "_, fine_tuning_training_history = train_model(\n",
    "    model=classification_model,\n",
    "    training_data=(leaves_train, roots_train),\n",
    "    test_data=(leaves_test, roots_test),\n",
    "    n_epochs=n_epochs,\n",
    "    loss_fn=loss_fn,\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=32,\n",
    "    early_stopper=None\n",
    ")\n",
    "\n",
    "plot_training_history(fine_tuning_training_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
